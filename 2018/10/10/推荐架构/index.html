<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>推荐架构 | Moby Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="[TOC] 推荐引擎算法协同过滤推荐算法在一个推荐系统中，存在三类关系：用户与用户（U-U矩阵）、物品与物品（V-V矩阵）和用户与物品（U-V矩阵）。 关系矩阵与矩阵计算U-U矩阵算法原理在基于用户相似度的协同过滤中，用户相似度的计算是基本前提。Pearson相关系数主要用于度量两个变量 i 和 j 之间的相关性，取值范围是+1（强正相关）到-1（强负相关） Iij为用户 i 和 j 共同评价过的">
<meta property="og:type" content="article">
<meta property="og:title" content="推荐架构">
<meta property="og:url" content="http://mobyIsMe.github.io/2018/10/10/推荐架构/index.html">
<meta property="og:site_name" content="Moby Blog">
<meta property="og:description" content="[TOC] 推荐引擎算法协同过滤推荐算法在一个推荐系统中，存在三类关系：用户与用户（U-U矩阵）、物品与物品（V-V矩阵）和用户与物品（U-V矩阵）。 关系矩阵与矩阵计算U-U矩阵算法原理在基于用户相似度的协同过滤中，用户相似度的计算是基本前提。Pearson相关系数主要用于度量两个变量 i 和 j 之间的相关性，取值范围是+1（强正相关）到-1（强负相关） Iij为用户 i 和 j 共同评价过的">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/94900278.jpg">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/48740525.jpg">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/57088537.jpg">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/6888260.jpg">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/55036067.jpg">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/23120071.jpg">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/44895826.jpg">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/80630137.jpg">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/30285749.jpg">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/87010752.jpg">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/7521046.jpg">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/29026798.jpg">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/90256800.jpg">
<meta property="og:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/37232195.jpg">
<meta property="og:updated_time" content="2018-10-29T15:37:01.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="推荐架构">
<meta name="twitter:description" content="[TOC] 推荐引擎算法协同过滤推荐算法在一个推荐系统中，存在三类关系：用户与用户（U-U矩阵）、物品与物品（V-V矩阵）和用户与物品（U-V矩阵）。 关系矩阵与矩阵计算U-U矩阵算法原理在基于用户相似度的协同过滤中，用户相似度的计算是基本前提。Pearson相关系数主要用于度量两个变量 i 和 j 之间的相关性，取值范围是+1（强正相关）到-1（强负相关） Iij为用户 i 和 j 共同评价过的">
<meta name="twitter:image" content="http://phal1xgub.bkt.clouddn.com/18-10-29/94900278.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Moby Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Moby Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">T_blog</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://mobyIsMe.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-推荐架构" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/10/推荐架构/" class="article-date">
  <time datetime="2018-10-10T12:52:47.000Z" itemprop="datePublished">2018-10-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      推荐架构
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>[TOC]</p>
<h4 id="推荐引擎算法"><a href="#推荐引擎算法" class="headerlink" title="推荐引擎算法"></a>推荐引擎算法</h4><h4 id="协同过滤推荐算法"><a href="#协同过滤推荐算法" class="headerlink" title="协同过滤推荐算法"></a>协同过滤推荐算法</h4><p>在一个推荐系统中，存在三类关系：用户与用户（U-U矩阵）、物品与物品（V-V矩阵）和用户与物品（U-V矩阵）。</p>
<h5 id="关系矩阵与矩阵计算"><a href="#关系矩阵与矩阵计算" class="headerlink" title="关系矩阵与矩阵计算"></a>关系矩阵与矩阵计算</h5><h6 id="U-U矩阵"><a href="#U-U矩阵" class="headerlink" title="U-U矩阵"></a>U-U矩阵</h6><p><strong>算法原理</strong><br>在基于用户相似度的协同过滤中，用户相似度的计算是基本前提。Pearson相关系数主要用于度量两个变量 i 和 j 之间的相关性，取值范围是+1（强正相关）到-1（强负相关）<br><img src="http://phal1xgub.bkt.clouddn.com/18-10-29/94900278.jpg" alt=""></p>
<p><strong>I</strong>ij为用户 i 和 j 共同评价过的物品的集合，c 是这个集合中的物品元素，<br><strong>r</strong>ic是用户 i 对物品 c 的评价值，<br><strong>算法流程：</strong></p>
<p>算法输入：用户行为日志。 </p>
<p>算法输出：基于协同的用户相似度矩阵。</p>
<ul>
<li>A. 从用户行为日志中获取用户与物品之间的关系数据，即用户对物品的评分数据。 </li>
<li>B. 对于n个用户，依次计算用户1与其他n-1个用户的相似度；再计算用户2与其他n-2个用户的相似度。对于其中任意两个用户 i 和 j ：<ul>
<li>a) 查找两个用户共同评价过的物品集</li>
<li>b) 分别计算用户 i 和对物品 j 的平均评价</li>
<li>c) 计算用户间相似度，得到用户 i 和 j 的相似度。</li>
</ul>
</li>
<li>C. 将计算得到的相似度结果存储于数据库中。</li>
</ul>
<h6 id="V-V矩阵"><a href="#V-V矩阵" class="headerlink" title="V-V矩阵"></a>V-V矩阵</h6><p><strong>算法原理：</strong><br>在基于物品相似度的协同过滤中，物品相似度的计算是基本前提。将物品的评价数值抽象为n维用户空间中的列向量<strong>x</strong>i,<strong>x</strong>j，分别代表用户 u 对物品<strong>x</strong>i，<strong>x</strong>j的评价值，<br>使用修正的余弦相似度，计算公式为：<br><img src="http://phal1xgub.bkt.clouddn.com/18-10-29/48740525.jpg" alt=""><br><strong>U</strong>xi,xj是对物品<strong>x</strong>i,<strong>x</strong>j共同评价过的用户集合，</p>
<p><strong>算法流程</strong></p>
<p>算法输入：用户行为日志。</p>
<p>算法输出：基于协同的物品相似度矩阵。 </p>
<ul>
<li>A. 从用户行为日志中获取用户与物品之间的关系数据，即用户对物品的评分数据。 </li>
<li>B. 对于n个物品，依次计算物品1与其他n-1个物品的相似度；再计算物品2与其他n-2个物品的相似度。对于其中任意两个物品 i 和 j： <ul>
<li>a) 查找对物品 i 和 j 共同评价过的用户集<strong>U</strong>ij</li>
<li>b) 分别计算用户对物品 i 和 j 的平均评价：<strong>r</strong>i,<strong>r</strong>j</li>
<li>c) 计算物品间相似度，得到物品 i 和 j 的相似度。</li>
</ul>
</li>
<li><p>C. 将计算得到的相似度结果存储于数据库中。</p>
<h6 id="U-V矩阵"><a href="#U-V矩阵" class="headerlink" title="U-V矩阵"></a>U-V矩阵</h6><p>在真实的推荐系统中，一方面U-V矩阵的行列数会随着用户和物品数量变得庞大，另一方面，因为用户实际上只能对有限数量的物品做出评价，所以U-V矩阵的内部会非常稀疏。系统在直接处理这些庞大稀疏矩阵时，耗费的时间、内存和计算资源都十分巨大。因此需要采取降低计算复杂度的方法。矩阵分解技术是一种有效降低矩阵计算复杂的方法，它的实质是将高维矩阵进行有效降维。</p>
</li>
<li><p>奇异值分解（SVD）</p>
<p>  SVD将给定矩阵分解为3个矩阵的乘积：<br>  <img src="http://phal1xgub.bkt.clouddn.com/18-10-29/57088537.jpg" alt=""><br>  中间的变量为对角矩阵，其对角线上的值为矩阵M的奇异值，按大小排列，代表着矩阵M的重要特征。将SVD用在推荐系统上，其意义是将一个系数的评分矩阵M分解为表示用户特性的U矩阵，表示物品特性的V矩阵，以及表示用户和物品相关性的矩阵。<br>  M = 用户特性的U矩阵<em> 用户和物品相关性的矩阵 </em>物品特性的V矩阵</p>
</li>
<li><p>主成分分析（PCA）<br> 在推荐系统中，对于有较多属性的物品（物品的信息用向量<br> <strong>m</strong> [<strong>i</strong>1,<strong>i</strong>2,<strong>i</strong>3….<strong>i</strong>n]<br> 表示）可用PCA处理进行降维，将m×n的物品矩阵转化为m×k的新矩阵。</p>
</li>
</ul>
<h5 id="memory-based的协同过滤算法"><a href="#memory-based的协同过滤算法" class="headerlink" title="memory-based的协同过滤算法"></a>memory-based的协同过滤算法</h5><p>基于记忆的cf可以分为两个步骤，<br>第一：找到目标之间的相似性<br>第二：根据相似性去推荐</p>
<h6 id="user-cf"><a href="#user-cf" class="headerlink" title="user-cf:"></a>user-cf:</h6><p> (1) 找到和目标用户兴趣相似的用户集合。<br> (2) 找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户。<br><strong>算法流程</strong><br>算法输入：用户行为日志，基于协同的用户相似性矩阵。<br>算法输出：初始推荐结果</p>
<ul>
<li>A. 访问用户行为日志，获取近期变化的用户ID集合U。</li>
<li>B. 针对集合U中每个用户 u：<ul>
<li>a) 访问用户相似矩阵，获取与用户相似的用户合集N(u)。 </li>
<li>b) 对于N(u)中的每一个用户ui： </li>
<li>获取与用户ui有关联的物品合集<strong>M</strong>ui</li>
<li>针对物品合集<strong>M</strong>ui中的每个物品，计算用户偏好值。 </li>
<li>c) 对集M(u)中的所有物品进行按照用户偏好进行加权、去重、排序。 </li>
<li>d) 取Top-N个物品，为每个物品赋予解释。 </li>
<li>e) 保存Top-N个物品到初始推荐列表中。</li>
</ul>
</li>
</ul>
<p><img src="http://phal1xgub.bkt.clouddn.com/18-10-29/6888260.jpg" alt=""></p>
<p>给定用户u和用户v，令N(u)表示用户u曾经有过正反馈的物品集合，令N(v) 为用户v曾经有过正反馈的物品集合。那么，我们可以通过如下的Jaccard公式简单地计算u和v的 兴趣相似度</p>
<p><strong>适用性</strong></p>
<p>由于需计算用户相似度矩阵，基于用户的协同过滤算法适用于用户较少的场合； 由于时效性较强，该方法适用于用户个性化兴趣不太明显的领域。</p>
<h6 id="item-cf"><a href="#item-cf" class="headerlink" title="item-cf"></a>item-cf</h6><p>基于物品的协同过滤（item-based collaborative filtering）算法是目前业界应用最多的算法。无论是亚马逊网，还是Netflix、Hulu、Youtube，其推荐算法的基础都是该算法。</p>
<p><strong>算法原理</strong></p>
<p>基于物品的协同过滤算法给用户推荐那些和他们之前喜欢的物品相似的物品。</p>
<p>temCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度。该算法认为，物品A和物品B具有很大的相似度是因为喜欢物品A的用户大都也喜欢物品B。</p>
<p><strong>算法流程</strong></p>
<p>假设用户为<strong>U</strong>i,物品<strong>M</strong>j,用户对物品的评分是<strong>r</strong>ij，<br>根据用户对物品<strong>M</strong>j的历史行为数据计算物品<strong>M</strong>j与其他已评分物品的相似度 <strong>Sim</strong>(j,i)，构成相似度物品集合<strong>N</strong>(u),根据所有物品<strong>N</strong>(u)的评分情况，选出N(u)中目标用户可能喜欢的且没有观看过的推荐给目标用户并预测评分。<br><img src="http://phal1xgub.bkt.clouddn.com/18-10-29/55036067.jpg" alt=""><br>ItemCF通过下面的公式来计算用户对物品的喜好程度：<br><img src="http://phal1xgub.bkt.clouddn.com/18-10-29/23120071.jpg" alt=""></p>
<p><strong>算法步骤：</strong></p>
<p>算法输入：用户行为日志，基于协同的物品相似性矩阵<br>算法输出：初始推荐结果</p>
<ul>
<li>A. 访问用户行为日志，获取该用户最近浏览过物品的用户集合U。 </li>
<li>B. 针对集合U中每个用户u：<ul>
<li>a) 访问用户相似矩阵，获取与用户相似的用户合集N(u)。 </li>
<li>b) 访问物品相似矩阵，获取与M(u)相似的物品合集N(u)。 </li>
<li>c) 针对物品合集M(ui)中的每个物品，计算用户偏好值。 </li>
<li>d) 根据用户偏好值，对N(u)的物品进行排序。 </li>
<li>e) 取Top-N个物品，为每个物品赋予解释。 </li>
<li>f) 保存Top-N个物品到初始推荐列表中。</li>
</ul>
</li>
</ul>
<p><img src="http://phal1xgub.bkt.clouddn.com/18-10-29/44895826.jpg" alt=""><br>  这里，分母|N(i)|是喜欢物品i的用户数，而分子 N(i)交N(j) 是同时喜欢物品i和物品j的用户数。因此，上述公式可以理解为喜欢物品i的用户中有多少比例的用户也喜欢物品j。</p>
<p> <strong>适用性</strong><br>适用于物品数明显小于用户数的场合； 长尾物品丰富，用户个性化需求强烈的领域。</p>
<h6 id="UserCF和ItemCF的比较"><a href="#UserCF和ItemCF的比较" class="headerlink" title="UserCF和ItemCF的比较"></a>UserCF和ItemCF的比较</h6><p>  <img src="http://phal1xgub.bkt.clouddn.com/18-10-29/80630137.jpg" alt=""></p>
<h4 id="content-basesd："><a href="#content-basesd：" class="headerlink" title="content-basesd："></a>content-basesd：</h4><p>基础CB推荐算法利用物品的基本信息和用户偏好内容的相似性进行物品推荐。通过分析用户已经浏览过的物品内容，生成用户的偏好内容，然后推荐与用户感兴趣的物品内容相似度高的其他物品。</p>
<p>比如，用户近期浏览过冯小刚导演的电影“非诚勿扰”，主演是葛优；那么如果用户没有看过“私人订制”，则可以推荐给用户。因为这两部电影的导演都是冯小刚，主演都有葛优。</p>
<p><strong>适用场景</strong></p>
<p>适用于基础CB架构的搭建，尤其是对新上线物品会马上被推荐非常有效，被推荐的机会与老的物品是相同的。</p>
<p><img src="http://phal1xgub.bkt.clouddn.com/18-10-29/30285749.jpg" alt=""><br>ui表用户，qi表物品，uik表示用户在第 k 个方面的特征，qik表示物品在第 k 个方面的特征，<br>sim（uik，qik）表示ui,qi在第 k 个特征方面上的相似度<br><strong>算法流程</strong></p>
<p>算法输入：物品信息，用户行为日志。<br>算法输出：初始推荐结果。</p>
<ul>
<li>A. 物品表示：每个物品使用特征向量<br><img src="http://phal1xgub.bkt.clouddn.com/18-10-29/87010752.jpg" alt=""></li>
<li>B. 从用户行为日志中，获取该用户所浏览、收藏、评价、分享的物品集合M，根据物品集合M中物品的特征数据，可以学到用户的内容偏好； </li>
<li>C. 保存Top-K个物品到初始推荐结果中。</li>
</ul>
<p><strong>适用场景</strong><br>适用于基础CB架构的搭建，尤其是对新上线物品会马上被推荐非常有效，被推荐的机会与老的物品是相同的。</p>
<h5 id="基于KNN的CB推荐算法"><a href="#基于KNN的CB推荐算法" class="headerlink" title="基于KNN的CB推荐算法"></a>基于KNN的CB推荐算法</h5><p>KNN(k-Nearest Neighbor)算法基于这样的假设：如果在特征空间中，一个样本的k个最邻近样本中的大多数样本属于某一个类别，则该样本也属于这个类别。<br>KNN在CB推荐算法中的应用于在CF推荐算法中的应用极为相似，它们都是要首先找到与目标物品相似的且已经被用户 u 评价过的 k 个物品，然后根据用户 u 对这 k 个物品的评价来预测其目标物品的评价。它们的差别在于，CF推荐算法中的KNN是根据用户对物品的评分来计算物品间相似度的，而CB推荐算法中KNN是根据物品画像来计算相似度的，所以对于后者来说，如何通过物品画像来计算物品间的相似度是算法中的关键步骤。相似度的计算可以使用余弦相似度或Pearson相关系数的计算方法。</p>
<p>算法输入：用户已评分物品，目标物品 i 。<br>算法输出：用户对目标物品 i 的评分。</p>
<h5 id="基于决策树的CB推荐算法"><a href="#基于决策树的CB推荐算法" class="headerlink" title="基于决策树的CB推荐算法"></a>基于决策树的CB推荐算法</h5><p>基于决策树的推荐算法在训练阶段会生成一个显示的决策模型。决策树可以通过训练数据构建并有效判断一个新的物品是否可能受到欢迎。当物品的特征属性较少时，采用决策树算法能够取得不错的效果，另外，决策树学习的思想也比较容易被理解，在物品推荐时的可解释性较好</p>
<p>在物品推荐系统中，决策树的内部节点通常表示物品的特征属性，这些节点用于区分物品集合，例如，通过物品中是否包含这个特征将其进行分类。在只有两个分类的简单数据集中，用户是否对物品感兴趣一般出现在决策树的叶子节点上。</p>
<h5 id="基于朴素贝叶斯的CB推荐算法"><a href="#基于朴素贝叶斯的CB推荐算法" class="headerlink" title="基于朴素贝叶斯的CB推荐算法"></a>基于朴素贝叶斯的CB推荐算法</h5><p>基于朴素贝叶斯的推荐系统假设用户和物品的特征向量中的各个分量之间条件独立，判断用户是否对某个物品有兴趣的方法是将这个问题转化为分类问题：喜欢和不喜欢。</p>
<h4 id="混合推荐算法"><a href="#混合推荐算法" class="headerlink" title="混合推荐算法"></a>混合推荐算法</h4><p>各种推荐方法都有优缺点，为了扬长补短，在实际中常常采用混合推荐（Hybrid Recommendation）。研究和应用最多的是内容推荐和协同过滤推荐的组合。最简单的做法就是分别用基于内容的方法和协同过滤推荐方法去产生一个推荐预测结果，然后用某方法组合其结果。尽管从理论上有很多种推荐组合方法，但在某一具体问题中并不见得都有效，组合推荐一个最重要原则就是通过组合后要能避免或弥补各自推荐技术的弱点。</p>
<h4 id="推荐系统的评估（Evaluation）"><a href="#推荐系统的评估（Evaluation）" class="headerlink" title="推荐系统的评估（Evaluation）"></a>推荐系统的评估（Evaluation）</h4><p>一个完整的推荐系统一般存在3个参与方：</p>
<ul>
<li>用户</li>
<li>物品提供者</li>
<li>提供推荐系统的网站</li>
</ul>
<p>好的推荐系统设计，能够让推荐系统本身收集到高质量的用户反馈，不断完善推荐的质量，增加用户和网站的交互，提高网站的收入。因此在评测一个推荐算法时，需要同时考虑三方的利益，一个好的推荐系统是能够令三方共赢的系统。</p>
<h5 id="推荐系统实验方法"><a href="#推荐系统实验方法" class="headerlink" title="推荐系统实验方法"></a>推荐系统实验方法</h5><p>一般来说，一个新的推荐算法最终上线，需要完成上面所说的3个实验：离线实验、用户调查和在线实验。</p>
<ul>
<li><p>离线实验的方法一般由如下几个步骤构成：</p>
<ul>
<li>通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集；</li>
<li>将数据集按照一定的规则分成训练集和测试集；</li>
<li>在训练集上训练用户兴趣模型，在测试集上进行预测；</li>
<li><p>通过事先定义的离线指标评测算法在测试集上的预测结果。</p>
<p>从上面的步骤可以看到，推荐系统的离线实验都是在数据集上完成的，也就是说它不需要一个实际的系统来供它实验，而只要有一个从实际系统日志中提取的数据集即可，因此离线实验速度快，可以测试大量算法，这是离线实验的显著优点。而它的主要缺点是无法获得很多商业上关注的指标，如点击率、转化率等，而找到和商业指标非常相关的离线指标也是很困难的事情。</p>
</li>
</ul>
</li>
<li><p>用户调查</p>
<p>  离线实验的指标和实际的商业指标存在差距，比如预测准确率和用户满意度之间就存在很大差别，高预测准确率不等于高用户满意度。因此，如果要准确评测一个算法，需要相对比较真实的环境。最好的方法就是将算法直接上线测试，但在对算法会不会降低用户满意度不太有把握的情况下，上线测试具有较高的风险，所以在上线测试前一般需要做一次称为用户调查的测试。</p>
<p>  测试用户的选择必须尽量保证测试用户的分布和真实用户的分布相同，比如男女各半，以及年龄、活跃度的分布都和真实用户分布尽量相同。此外，用户调查要尽量保证是双盲实验，不要让实验人员和用户事先知道测试的目标，以免用户的回答和实验人员的测试受主观成分的影响。</p>
<p>  用户调查的优缺点也很明显。它的优点是可以获得很多体现用户主观感受的指标，相对在线实验风险很低，出现错误后很容易弥补。缺点是招募测试用户代价较大，很难组织大规模的测试用户，因此会使测试结果的统计意义不足。此外，在很多时候设计双盲实验非常困难，而且用户在测试环境下的行为和真实环境下的行为可能有所不同，因而在测试环境下收集的测试指标可能在真实环境下无法重现。</p>
</li>
<li><p>在线实验<br><img src="http://phal1xgub.bkt.clouddn.com/18-10-29/7521046.jpg" alt=""><br>在完成离线实验和必要的用户调查后，可以将推荐系统上线做AB测试，将它和旧的算法进行比较。<strong>AB测试是一种很常用的在线评测算法的实验方法。</strong>它通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后通过统计不同组用户的各种不同的评测指标比较不同算法，比如可以统计不同组用户的点击率，通过点击率比较不同算法的性能。对AB测试感兴趣的读者可以浏览一下网站 <a href="http://www.abtests.com/，" target="_blank" rel="noopener">http://www.abtests.com/，</a> 该网站给出了很多通过实际AB测试提高网站用户满意度的例子，从中我们可以学习到如何进行合理的AB测试。</p>
</li>
</ul>
<p>AB测试的优点是可以公平获得不同算法实际在线时的性能指标，包括商业上关注的指标。AB测试的缺点主要是周期比较长，必须进行长期的实验才能得到可靠的结果。因此一般不会用AB测试测试所有的算法，而只是用它测试那些在离线实验和用户调查中表现很好的算法。其次，一个大型网站的AB测试系统的设计也是一项复杂的工程。一个大型网站的架构分前端和后端，从前端展示给用户的界面到最后端的算法，中间往往经过了很多层，这些层往往由不同的团队控制，而且都有可能做AB测试。</p>
<p>如果为不同的层分别设计AB测试系统，那么不同的AB测试之间往往会互相干扰。比如，当我们进行一个后台推荐算法的AB测试，同时网页团队在做推荐页面的界面AB测试，最终的结果就是你不知道测试结果是自己算法的改变，还是推荐界面的改变造成的。因此，切分流量是AB测试中的关键，不同的层以及控制这些层的团队需要从一个统一的地方获得自己AB测试的流量，而不同层之间的流量应该是正交的。</p>
<h4 id="评测指标"><a href="#评测指标" class="headerlink" title="评测指标"></a>评测指标</h4><ul>
<li><p>预测准确度</p>
<p>  预测准确度衡量一个推荐系统或者推荐算法预测用户行为的能力，是最重要的推荐系统离线评测指标。从推荐系统诞生的那一天起，几乎99%与推荐相关的论文都在讨论这个指标。这主要是因为该指标可以通过离线实验计算，方便了很多学术界的研究人员研究推荐算法。</p>
</li>
</ul>
<ul>
<li><p>TopN推荐</p>
<p>网站在提供推荐服务时，一般是给用户一个个性化的推荐列表，这种推荐叫做TopN推荐。TopN推荐的预测准确率一般通过准确率（precision）/召回率（recall）度量。令 R(u) 是根据用户在训练集上的行为给用户作出的推荐列表，而 T(u) 是用户在测试集上的行为列表。那么，推荐结果的召回率定义为：</p>
<p>  <img src="http://phal1xgub.bkt.clouddn.com/18-10-29/29026798.jpg" alt=""></p>
<p>  推荐结果的精准率定义为：</p>
<p>  <img src="http://phal1xgub.bkt.clouddn.com/18-10-29/90256800.jpg" alt=""></p>
</li>
<li><p>覆盖率 </p>
<p>  覆盖率（coverage）描述一个推荐系统对物品长尾的发掘能力。覆盖率有不同的定义方法，最简单的定义为推荐系统能够推荐出来的物品占总物品集合的比例。假设系统的用户集合为 U，推荐系统给每个用户推荐一个长度为N的物品列表R(u)。那么推荐系统的覆盖率可以通过下面的公式计算： </p>
<p>  <img src="http://phal1xgub.bkt.clouddn.com/18-10-29/37232195.jpg" alt=""></p>
<p>  覆盖率是一个内容提供商会关心的指标。以图书推荐为例，出版社可能会很关心他们的书有没有被推荐给用户。覆盖率为100%的推荐系统可以将每个物品都推荐给至少一个用户。此外，从上面的定义也可以看到，热门排行榜的推荐覆盖率是很低的，它只会推荐那些热门的物品，这些物品在总物品中占的比例很小。一个好的推荐系统不仅需要有比较高的用户满意度，也要有较高的覆盖率。</p>
</li>
<li><p>多样性</p>
<p>  为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性。尽管用户的兴趣在较长的时间跨度中是一样的，但具体到用户访问推荐系统的某一刻，其兴趣往往是单一的，那么如果推荐列表只能覆盖用户的一个兴趣点，而这个兴趣点不是用户这个时刻的兴趣点，推荐列表就不会让用户满意。反之，如果推荐列表比较多样，覆盖了用户绝大多数的兴趣点，那么就会增加用户找到感兴趣物品的概率。因此给用户的推荐列表也需要满足用户广泛的兴趣，即具有多样性。<br>  <strong>多样性描述了推荐列表中物品两两之间的不相似性。因此，多样性和相似性是对应的。</strong></p>
</li>
<li><p>新颖性<br>新颖的推荐是指给用户推荐那些他们以前没有听说过的物品。在一个网站中实现新颖性的最简单办法是，把那些用户之前在网站中对其有过行为的物品从推荐列表中过滤掉。比如在一个视频网站中，新颖的推荐不应该给用户推荐那些他们已经看过、打过分或者浏览过的视频。但是，有些视频可能是用户在别的网站看过，或者是在电视上看过，因此仅仅过滤掉本网站中用户有过行为的物品还不能完全实现新颖性。</p>
<p>  但是，用推荐结果的平均流行度度量新颖性比较粗略，因为不同用户不知道的东西是不同的。因此，要准确地统计新颖性需要做用户调查。</p>
</li>
<li><p>惊喜度</p>
<p>  惊喜度（serendipity）是最近这几年推荐系统领域最热门的话题。令用户惊喜的推荐结果是和用户历史上喜欢的物品不相似，但用户却觉得满意的推荐。那么，定义惊喜度需要首先定义推荐结果和用户历史上喜欢的物品的相似度，其次需要定义用户对推荐结果的满意度。</p>
</li>
</ul>
<pre><code>用户满意度只能通过问卷调查或者在线实验获得，而推荐结果和用户历史上喜欢的物品相似度一般可以用内容相似度定义。也就是说，如果获得了一个用户观看电影的历史，得到这些电影的演员和导演集合A，然后给用户推荐一个不属于集合A的导演和演员创作的电影，而用户表示非常满意，这样就实现了一个惊喜度很高的推荐。因此提高推荐惊喜度需要提高推荐结果的用户满意度，同时降低推荐结果和用户历史兴趣的相似度。
</code></pre><h4 id="推荐系统的冷启动问题（Cold-Start）"><a href="#推荐系统的冷启动问题（Cold-Start）" class="headerlink" title="推荐系统的冷启动问题（Cold Start）"></a>推荐系统的冷启动问题（Cold Start）</h4><p>推荐系统需要根据用户的历史行为和兴趣预测用户未来的行为和兴趣，对于BAT这类大公司来说，它们已经积累了大量的用户数据，不发愁。但是对于很多做纯粹推荐系统的网站或者很多在开始阶段就希望有个性化推荐应用的网站来说，如何在对用户一无所知（即没有用户行为数据）的情况下进行最有效的推荐呢？这就衍生了冷启动问题。</p>
<p><strong>冷启动问题主要分为3类：</strong></p>
<ul>
<li>用户冷启动，即如何给新用户做个性化推荐</li>
<li>物品冷启动，即如何将新的物品推荐给可能对它感兴趣的用户</li>
<li>系统冷启动，即如何在一个新开发的网站（没有用户，没有用户行为，只有部分物品信息）上设计个性化推荐系统，从而在网站刚发布时就让用户体会到个性化推荐</li>
</ul>
<p><strong>冷启动问题的解决方案</strong></p>
<ul>
<li>提供非个性化的推荐<br>最简单的例子就是提供热门排行榜，可以给用户推荐热门排行榜，等到用户数据收集到一定的时候，再切换为个性化推荐。Netflix的研究也表明新用户在冷启动阶段确实是更倾向于热门排行榜的，老用户会更加需要长尾推荐。</li>
<li><p>利用用户注册信息</p>
<p>  用户的注册信息主要分为3种：<br>  人口统计学信息，包括年龄、性别、职业、民族、学历和居住地<br>  用户兴趣的描述，部分网站会让用户用文字来描述兴趣<br>  从其他网站导入的用户站外行为，比如用户利用社交网站账号登录，就可以在获得用户授权的情况下导入用户在该社交网站的部分行为数据和社交网络数据。</p>
<p>  这种个性化的粒度很粗，假设性别作为一个粒度来推荐，那么所有刚注册的女性看到的都是同样的结果，但是相对于男女不区分的方式，这种推荐精度已经大大提高了。</p>
</li>
</ul>
<ul>
<li><p>选择合适的物品启动用户的兴趣</p>
<p>  用户在登录时对一些物品进行反馈，收集用户对这些物品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。一般来说，能够用来启动用户兴趣的物品需要具有以下特点：</p>
<p>  比较热门，如果要让用户对物品进行反馈，前提是用户得知道这是什么东西；<br>  具有代表性和区分性，启动用户兴趣的物品不能是大众化或老少咸宜的，因为这样的物品对用户的兴趣没有区分性；<br>  启动物品集合需要有多样性，在冷启动时，我们不知道用户的兴趣，而用户兴趣的可能性非常多，为了匹配多样的兴趣，我们需要提供具有很高覆盖率的启动物品集合，这些物品能覆盖几乎所有主流的用户兴趣。</p>
</li>
<li><p>利用物品的内容信息</p>
<p>  物品冷启动问题在新闻网站等时效性很强的网站中非常重要，因为这些网站时时刻刻都有新物品加入，而且每个物品必须能够再第一时间展现给用户，否则经过一段时间后，物品的价值就大大降低了。</p>
</li>
</ul>
<pre><code>对UserCF算法来说，针对推荐列表并不是给用户展示内容的唯一列表（大多网站都是这样的）的网站。当新物品加入时，总会有用户通过某些途径看到，那么当一个用户对其产生反馈后，和他历史兴趣相似的用户的推荐列表中就有可能出现该物品，从而更多的人对该物品做出反馈，导致更多的人的推荐列表中出现该物品。



因此，该物品就能不断扩散开来，从而逐步展示到对它感兴趣用户的推荐列表中针对推荐列表是用户获取信息的主要途径（例如豆瓣网络电台）的网站UserCF算法就需要解决第一推动力的问题，即第一个用户从哪儿发现新物品。最简单的方法是将新的物品随机战士给用户，但是太不个性化。因此可以考虑利用物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户。



对ItemCF算法来说，物品冷启动就是很严重的问题了。因为该算法的基础是通过用户对物品产生的行为来计算物品之间的相似度，当新物品还未展示给用户时，用户就无法产生行为。为此，只能利用物品的内容信息计算物品的相关程度。基本思路就是将物品转换成关键词向量，通过计算向量之间的相似度（例如计算余弦相似度），得到物品的相关程度。
</code></pre><ul>
<li><p>采用专家标注</p>
<p>  很多系统在建立的时候，既没有用户的行为数据，也没有充足的物品内容信息来计算物品相似度。这种情况下，很多系统都利用专家进行标注。</p>
</li>
</ul>
<pre><code>代表系统：个性化网络电台Pandora、电影推荐网站Jinni。



以Pandora电台为例，Pandora雇用了一批音乐人对几万名歌手的歌曲进行各个维度的标注，最终选定了400多个特征。每首歌都可以标识为一个400维的向量，然后通过常见的向量相似度算法计算出歌曲的相似度。
</code></pre><h4 id="推荐系统学术研究常用数据集"><a href="#推荐系统学术研究常用数据集" class="headerlink" title="推荐系统学术研究常用数据集"></a>推荐系统学术研究常用数据集</h4><ul>
<li><p>MovieLen(<a href="https://grouplens.org/datasets/movielens/" target="_blank" rel="noopener">https://grouplens.org/datasets/movielens/</a>)</p>
<p>  MovieLens数据集中，用户对自己看过的电影进行评分，分值为1~5。MovieLens包括两个不同大小的库，适用于不同规模的算法。小规模的库是943个独立用户对1 682部电影作的10 000次评分的数据；大规模的库是6 040个独立用户对3 900部电影作的大约100万次评分。</p>
</li>
<li><p>BookCrossing(<a href="http://www2.informatik.uni-freiburg.de/~cziegler/BX/" target="_blank" rel="noopener">http://www2.informatik.uni-freiburg.de/~cziegler/BX/</a>) </p>
<p>  这个数据集是网上的Book-Crossing图书社区的278858个用户对271379本书进行的评分，包括显式和隐式的评分。这些用户的年龄等人口统计学属性(demographic feature)都以匿名的形式保存并供分析。这个数据集是由Cai-Nicolas Ziegler使用爬虫程序在2004年从Book-Crossing图书社区上采集的。</p>
</li>
<li><p>Jester Joke(<a href="http://eigentaste.berkeley.edu/dataset/" target="_blank" rel="noopener">http://eigentaste.berkeley.edu/dataset/</a>) </p>
</li>
</ul>
<p>Jester Joke是一个网上推荐和分享笑话的网站。这个数据集有73496个用户对100个笑话作的410万次评分。评分范围是−10~10的连续实数。这些数据是由加州大学伯克利分校的Ken Goldberg公布的。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mobyIsMe.github.io/2018/10/10/推荐架构/" data-id="cjxxcnnhx0008fur095il2oj8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/10/16/hello-world/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Hello World
        
      </div>
    </a>
  
  
    <a href="/2018/10/10/kaggle-titanic/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">kaggle-titanic</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据分析，数据挖掘/">数据分析，数据挖掘</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/数据分析，数据挖掘/" style="font-size: 10px;">数据分析，数据挖掘</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/05/10/特征选择/">特征选择</a>
          </li>
        
          <li>
            <a href="/2018/10/16/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2018/10/10/推荐架构/">推荐架构</a>
          </li>
        
          <li>
            <a href="/2018/10/10/kaggle-titanic/">kaggle-titanic</a>
          </li>
        
          <li>
            <a href="/2018/10/01/movielens/">movielens</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 moby<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>